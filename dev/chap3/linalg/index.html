<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Matrix Computation · Scientific Computing For Physicists</title><meta name="title" content="Matrix Computation · Scientific Computing For Physicists"/><meta property="og:title" content="Matrix Computation · Scientific Computing For Physicists"/><meta property="twitter:title" content="Matrix Computation · Scientific Computing For Physicists"/><meta name="description" content="Documentation for Scientific Computing For Physicists."/><meta property="og:description" content="Documentation for Scientific Computing For Physicists."/><meta property="twitter:description" content="Documentation for Scientific Computing For Physicists."/><meta property="og:url" content="https://book.jinguo-group.science/chap3/linalg/"/><meta property="twitter:url" content="https://book.jinguo-group.science/chap3/linalg/"/><link rel="canonical" href="https://book.jinguo-group.science/chap3/linalg/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Scientific Computing For Physicists</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Become an Open-source Developer</span><ul><li><a class="tocitem" href="../../chap1/terminal/">Get a Terminal!</a></li><li><a class="tocitem" href="../../chap1/git/">Maintainability - Version Control</a></li><li><a class="tocitem" href="../../chap1/ci/">Correctness - Unit Tests</a></li></ul></li><li><span class="tocitem">Julia Programming Language</span><ul><li><a class="tocitem" href="../../chap2/julia-setup/">Setup Julia</a></li><li><a class="tocitem" href="../../chap2/julia-why/">Why Julia?</a></li><li><a class="tocitem" href="../../chap2/julia-type/">Types and Multiple-dispatch</a></li><li><a class="tocitem" href="../../chap2/julia-array/">Array and Broadcasting</a></li><li><a class="tocitem" href="../../chap2/julia-release/">My First Package</a></li><li><a class="tocitem" href="../../chap2/julia-fluid/">Project: Fluid dynamics</a></li></ul></li><li><span class="tocitem">Linear Algebra</span><ul><li class="is-active"><a class="tocitem" href>Matrix Computation</a><ul class="internal"><li><a class="tocitem" href="#Matrix-multiplication"><span>Matrix multiplication</span></a></li><li><a class="tocitem" href="#System-of-Linear-Equations-and-LU-Decomposition"><span>System of Linear Equations and LU Decomposition</span></a></li><li><a class="tocitem" href="#Least-Squares-Problem-and-QR-Decomposition"><span>Least Squares Problem and QR Decomposition</span></a></li><li><a class="tocitem" href="#Eigenvalues-and-Eigenvectors"><span>Eigenvalues and Eigenvectors</span></a></li><li><a class="tocitem" href="#Matrix-functions"><span>Matrix functions</span></a></li><li><a class="tocitem" href="#Singular-Value-Decomposition"><span>Singular Value Decomposition</span></a></li><li><a class="tocitem" href="#Cholesky-Decomposition"><span>Cholesky Decomposition</span></a></li></ul></li><li><a class="tocitem" href="../lu/">Solving linear equations by LU factorization: Bottom-up</a></li><li><a class="tocitem" href="../qr/">QR Factorization: Bottom-up</a></li><li><a class="tocitem" href="../fft/">Fast Fourier transform</a></li><li><a class="tocitem" href="../sensitivity/">Sensitivity Analysis</a></li><li><a class="tocitem" href="../tensors/">Tensor Operations</a></li><li><a class="tocitem" href="../cuda/">Arrays on GPU</a></li><li><a class="tocitem" href="../sparse/">Sparse Matrices and Graphs</a></li></ul></li><li><span class="tocitem">Appendix</span><ul><li><a class="tocitem" href="../../append/plotting/">Plotting recipes with CairoMakie</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Linear Algebra</a></li><li class="is-active"><a href>Matrix Computation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Matrix Computation</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/GiggleLiu/ScientificComputingForPhysicists" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/GiggleLiu/ScientificComputingForPhysicists/blob/main/docs/src/chap3/linalg.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Matrix-Computation"><a class="docs-heading-anchor" href="#Matrix-Computation">Matrix Computation</a><a id="Matrix-Computation-1"></a><a class="docs-heading-anchor-permalink" href="#Matrix-Computation" title="Permalink"></a></h1><h2 id="Matrix-multiplication"><a class="docs-heading-anchor" href="#Matrix-multiplication">Matrix multiplication</a><a id="Matrix-multiplication-1"></a><a class="docs-heading-anchor-permalink" href="#Matrix-multiplication" title="Permalink"></a></h2><p>Matrix multiplication is a fundamental operation in linear algebra. Given two matrices <span>$A\in \mathbb{C}^{m\times n}$</span> and <span>$B\in \mathbb{C}^{n\times p}$</span>, the product <span>$C = AB$</span> is defined as</p><p class="math-container">\[C_{ij} = \sum_{k=1}^n A_{ik}B_{kj}.\]</p><p>The time complexity of matrix multiplication is <span>$O(mnp)$</span>.</p><h2 id="System-of-Linear-Equations-and-LU-Decomposition"><a class="docs-heading-anchor" href="#System-of-Linear-Equations-and-LU-Decomposition">System of Linear Equations and LU Decomposition</a><a id="System-of-Linear-Equations-and-LU-Decomposition-1"></a><a class="docs-heading-anchor-permalink" href="#System-of-Linear-Equations-and-LU-Decomposition" title="Permalink"></a></h2><p>Let <span>$A\in \mathbb{C}^{n\times n}$</span> be a invertible square matrix and <span>$b \in \mathbb{C}^n$</span> be a vector. Solving a linear equation means finding a vector <span>$x\in\mathbb{C}^n$</span> such that</p><p class="math-container">\[A x = b\]</p><div class="admonition is-info"><header class="admonition-header">Example</header><div class="admonition-body"><p>Let us consider the following system of linear equations</p><p class="math-container">\[\begin{align*}
2 x_1 + 3 x_2 - 2 x_3 &amp;= 1, \\
3 x_1 + 2 x_2 + 3 x_3 &amp;= 2, \\
4 x_1 - 3 x_2 + 2 x_3 &amp;= 3.
\end{align*}\]</p><p>The system of linear equations can be written in matrix form as</p><p class="math-container">\[\begin{bmatrix}
2 &amp; 3 &amp; -2 \\
3 &amp; 2 &amp; 3 \\
4 &amp; -3 &amp; 2
\end{bmatrix}
\begin{bmatrix}
x_1 \\
x_2 \\
x_3
\end{bmatrix}
=
\begin{bmatrix}
1 \\
2 \\
3
\end{bmatrix}.\]</p><p>In Julia, we can solve the system of linear equations using the backslash operator <code>\</code> function.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; A = [2 3 -2; 3 2 3; 4 -3 2]</code><code class="nohighlight hljs ansi" style="display:block;">3×3 Matrix{Int64}:
 2   3  -2
 3   2   3
 4  -3   2</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; b = [1, 2, 3]</code><code class="nohighlight hljs ansi" style="display:block;">3-element Vector{Int64}:
 1
 2
 3</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; x = A \ b</code><code class="nohighlight hljs ansi" style="display:block;">3-element Vector{Float64}:
  0.6666666666666666
 -0.07692307692307693
  0.05128205128205128</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; A * x</code><code class="nohighlight hljs ansi" style="display:block;">3-element Vector{Float64}:
 0.9999999999999999
 2.0
 3.0</code></pre><p>The <code>\</code> method is implemented with the LU decomposition. It is equivalent to the following code.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; using LinearAlgebra</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; lures = lu(A)  # pivot rows by default</code><code class="nohighlight hljs ansi" style="display:block;">LinearAlgebra.LU{Float64, Matrix{Float64}, Vector{Int64}}
L factor:
3×3 Matrix{Float64}:
 1.0   0.0       0.0
 0.5   1.0       0.0
 0.75  0.944444  1.0
U factor:
3×3 Matrix{Float64}:
 4.0  -3.0   2.0
 0.0   4.5  -3.0
 0.0   0.0   4.33333</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; lures.L * lures.U ≈ lures.P * A</code><code class="nohighlight hljs ansi" style="display:block;">true</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; UpperTriangular(lures.U) \ (LowerTriangular(lures.L) \ (lures.P * b))</code><code class="nohighlight hljs ansi" style="display:block;">3-element Vector{Float64}:
  0.6666666666666666
 -0.07692307692307693
  0.05128205128205128</code></pre></div></div><p>The LU decomposition of a matrix <span>$A\in \mathbb{C}^{n\times n}$</span> is a factorization of the form</p><p class="math-container">\[PA = LU\]</p><p>where <span>$P$</span> is a permutation matrix for pivoting the rows of <span>$A$</span>, <span>$L$</span> is a lower triangular matrix, and <span>$U$</span> is an upper triangular matrix. Pivoting rows are used to avoid division by zero to ensure numerical stability. In Julia, linear equations with <code>UpperTriangular</code> or <code>LowerTriangular</code> matrices will be solved with forward and backward substitution.</p><p>To summarize, the algorithm to solve a linear equation contains following steps:</p><ol><li><p>Decompose the matrix <span>$PA \in \mathbb{C}^{n\times n}$</span> into <span>$L \in \mathbb{C}^{n\times n}$</span> and <span>$U \in \mathbb{C}^{n\times n}$</span> matrices using a method such as <a href="../lu/#LU-Factorization-with-Gaussian-Elimination">Gaussian elimination</a> or Crout&#39;s method.</p></li><li><p>Rewrite the equation <span>$Ax = b$</span> as <span>$LUx = Pb$</span>.</p></li><li><p>Solve for y in <span>$Ly = b$</span> by <a href="../lu/#Forward-substitution">Forward-substitution</a>. This involves substituting the values of <span>$y$</span> into the equation one at a time, starting with the first row and working downwards.</p></li><li><p>Solve for <span>$x$</span> in <span>$Ux = y$</span> by <a href="../lu/#Back-substitution">Back-substitution</a> (link TBA). This involves substituting the values of <span>$x$</span> into the equation one at a time, starting with the last row and working upwards.</p></li></ol><h2 id="Least-Squares-Problem-and-QR-Decomposition"><a class="docs-heading-anchor" href="#Least-Squares-Problem-and-QR-Decomposition">Least Squares Problem and QR Decomposition</a><a id="Least-Squares-Problem-and-QR-Decomposition-1"></a><a class="docs-heading-anchor-permalink" href="#Least-Squares-Problem-and-QR-Decomposition" title="Permalink"></a></h2><p>The least squares problem is to find a vector <span>$x\in\mathbb{C}^n$</span> that minimizes the residual</p><p class="math-container">\[\|Ax - b\|_2\]</p><p>where <span>$A\in \mathbb{C}^{m\times n}$</span> and <span>$b\in \mathbb{C}^m$</span>. A solution to the least squares problem involves finding the QR decomposition of the matrix <span>$A$</span>. The QR decomposition of <span>$A$</span> is a factorization of the form</p><p class="math-container">\[A = QR\]</p><p>where <span>$Q\in \mathbb{C}^{m\times m}$</span> is an orthogonal matrix and <span>$R\in \mathbb{C}^{m\times n}$</span> is an upper triangular matrix. The QR decomposition is used to solve the linear least squares problem and to find the eigenvalues of a matrix.</p><p>In Julia, we can find the QR decomposition of a matrix using the <code>qr</code> function.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; A = [1 2; 3 4; 5 6]</code><code class="nohighlight hljs ansi" style="display:block;">3×2 Matrix{Int64}:
 1  2
 3  4
 5  6</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; qr(A)</code><code class="nohighlight hljs ansi" style="display:block;">LinearAlgebra.QRCompactWY{Float64, Matrix{Float64}, Matrix{Float64}}
Q factor: 3×3 LinearAlgebra.QRCompactWYQ{Float64, Matrix{Float64}, Matrix{Float64}}
R factor:
2×2 Matrix{Float64}:
 -5.91608  -7.43736
  0.0       0.828079</code></pre><div class="admonition is-info"><header class="admonition-header">Example: data fitting</header><div class="admonition-body"><p>Suppose we have a set of data points</p><table><tr><th style="text-align: right"><span>$t_i$</span></th><th style="text-align: right">0.0</th><th style="text-align: right">0.5</th><th style="text-align: right">1.0</th><th style="text-align: right">1.5</th><th style="text-align: right">2.0</th><th style="text-align: right">2.5</th><th style="text-align: right">3.0</th><th style="text-align: right">3.5</th><th style="text-align: right">4.0</th><th style="text-align: right">4.5</th></tr><tr><td style="text-align: right"><span>$y_i$</span></td><td style="text-align: right">2.9</td><td style="text-align: right">2.7</td><td style="text-align: right">4.8</td><td style="text-align: right">5.3</td><td style="text-align: right">7.1</td><td style="text-align: right">7.6</td><td style="text-align: right">7.7</td><td style="text-align: right">7.6</td><td style="text-align: right">9.4</td><td style="text-align: right">9.0</td></tr></table><img src="../../assets/images/fitting-data.png" alt="fitting data" width="400"/><p>We can fit a quadratic function of the form <span>$y = c_0 + c_1 t + c_2 t^2$</span> to the data by solving the least squares problem. We can solve the least squares problem by finding the values of <span>$c_0$</span>, <span>$c_1$</span>, and <span>$c_2$</span> that minimize the sum of the squared residuals</p><p class="math-container">\[\sum_{i=1}^n (y_i - (c_0 + c_1 t_i + c_2 t_i^2))^2.\]</p><p>In matrix form, the least squares problem can be written as</p><p class="math-container">\[\min_x \|Ax - b\|_2\]</p><p>where</p><p class="math-container">\[A = \begin{bmatrix}
1 &amp; t_1 &amp; t_1^2 \\
1 &amp; t_2 &amp; t_2^2 \\
\vdots &amp; \vdots &amp; \vdots \\
1 &amp; t_n &amp; t_n^2
\end{bmatrix},
x = \begin{bmatrix}
c_0 \\
c_1 \\
c_2
\end{bmatrix},
b = \begin{bmatrix}
y_1 \\
y_2 \\
\vdots \\
y_n
\end{bmatrix}.\]</p><p>By expanding the expression <span>$\|Ax - b\|_2$</span>, we can see that the solution to the least squares problem is given by</p><p class="math-container">\[x = (A^\dagger A)^{-1} A^\dagger b\]</p><p>when <span>$A^\dagger A$</span> is invertible, where <span>$A^\dagger$</span> is the Hermitian conjugate of <span>$A$</span>, which is the same as transpose given <span>$A$</span> is real. </p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; using LinearAlgebra</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; time = [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5];</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; y = [2.9, 2.7, 4.8, 5.3, 7.1, 7.6, 7.7, 7.6, 9.4, 9.0];</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; A = hcat(ones(length(time)), time, time.^2)</code><code class="nohighlight hljs ansi" style="display:block;">10×3 Matrix{Float64}:
 1.0  0.0   0.0
 1.0  0.5   0.25
 1.0  1.0   1.0
 1.0  1.5   2.25
 1.0  2.0   4.0
 1.0  2.5   6.25
 1.0  3.0   9.0
 1.0  3.5  12.25
 1.0  4.0  16.0
 1.0  4.5  20.25</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; x = (A&#39; * A) \ (A&#39; * y)</code><code class="nohighlight hljs ansi" style="display:block;">3-element Vector{Float64}:
  2.378181818181825
  2.4924242424242355
 -0.22121212121212</code></pre><p>The fitted quadratic function is as follows.</p><img src="../../assets/images/fitting-data2.png" alt="fitting data" width="400"/><p>However, this approach is not recommended for large matrices due to the poor <a href="../sensitivity/#Sensitivity-Analysis">numerical stability</a>. The condition number of <span>$A^\dagger A$</span> is the square of the condition number of <span>$A$</span>, which can be very large. Instead, we can use the <code>qr</code> function to solve the least squares problem.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; Q, R = qr(A)</code><code class="nohighlight hljs ansi" style="display:block;">LinearAlgebra.QRCompactWY{Float64, Matrix{Float64}, Matrix{Float64}}
Q factor: 10×10 LinearAlgebra.QRCompactWYQ{Float64, Matrix{Float64}, Matrix{Float64}}
R factor:
3×3 Matrix{Float64}:
 -3.16228  -7.11512  -22.5312
  0.0       4.54148   20.4366
  0.0       0.0        5.74456</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; x = R \ (Matrix(Q)&#39; * y)</code><code class="nohighlight hljs ansi" style="display:block;">3-element Vector{Float64}:
  2.378181818181821
  2.4924242424242427
 -0.22121212121212142</code></pre><p>An alternative way is to use the pseudoinverse of <span>$A$</span>, which invokes the more costly SVD decomposition.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; LinearAlgebra.pinv(A) * (y)  # an alternative way</code><code class="nohighlight hljs ansi" style="display:block;">3-element Vector{Float64}:
  2.37818181818182
  2.492424242424241
 -0.22121212121212186</code></pre></div></div><h2 id="Eigenvalues-and-Eigenvectors"><a class="docs-heading-anchor" href="#Eigenvalues-and-Eigenvectors">Eigenvalues and Eigenvectors</a><a id="Eigenvalues-and-Eigenvectors-1"></a><a class="docs-heading-anchor-permalink" href="#Eigenvalues-and-Eigenvectors" title="Permalink"></a></h2><p>The eigenvalues and eigenvectors of a matrix <span>$A\in \mathbb{C}^{n\times n}$</span> are the solutions to the equation</p><p class="math-container">\[A x = \lambda x\]</p><p>where <span>$\lambda$</span> is a scalar and <span>$x$</span> is a non-zero vector. The eigenvalues of a matrix can be found by solving the characteristic equation</p><p class="math-container">\[\det(A - \lambda I) = 0\]</p><p>where <span>$I$</span> is the identity matrix. The eigenvectors can be found by solving the equation <span>$(A - \lambda I)x = 0$</span>.</p><p>In Julia, we can find the eigenvalues and eigenvectors of a matrix using the <code>eigen</code> function.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; A = [1 2; 3 4]</code><code class="nohighlight hljs ansi" style="display:block;">2×2 Matrix{Int64}:
 1  2
 3  4</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; eigen(A)</code><code class="nohighlight hljs ansi" style="display:block;">LinearAlgebra.Eigen{Float64, Float64, Matrix{Float64}, Vector{Float64}}
values:
2-element Vector{Float64}:
 -0.3722813232690143
  5.372281323269014
vectors:
2×2 Matrix{Float64}:
 -0.824565  -0.415974
  0.565767  -0.909377</code></pre><div class="admonition is-info"><header class="admonition-header">Example: eigenmodes of a vibrating string (or atomic chain)</header><div class="admonition-body"><p>This example is about solving the dynamics of a vibrating string. <img src="../../assets/images/spring.png" alt/></p><p><a href="https://lampz.tugraz.at/~hadley/ss1/phonons/1d/1dphonons.php">Image source and main reference</a></p><p>The dynamics of a one dimensional vibrating string can be described by the Newton&#39;s second law</p><p class="math-container">\[M \ddot{u} = C(u_{i+1} - u_i) - C(u_i - u_{i-1})\]</p><p>where <span>$M$</span> is the mass matrix, <span>$C$</span> is the stiffness, and <span>$u_i$</span> is the displacement of the <span>$i$</span>th atom. The end atoms are fixed, so we have <span>$u_0 = u_{n+1} = 0$</span>. We assume all atoms have the same eigenfrequency <span>$\omega$</span> and the displacement of the <span>$i$</span>th atom is given by</p><p class="math-container">\[u_i(t) = A_i \cos(\omega t + \phi_i)\]</p><p>where <span>$\phi_i$</span> is the phase of the <span>$i$</span>th atom. Then we transform the equation into the eigenvalue problem</p><p class="math-container">\[\begin{bmatrix}
-C &amp; C &amp; 0 &amp; \cdots &amp; 0 \\
C &amp; -2C &amp; C &amp; \cdots &amp; 0 \\
0 &amp; C &amp; -2C &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; 0 &amp; \cdots &amp; -C
\end{bmatrix}
\begin{bmatrix}
A_1 \\
A_2 \\
A_3 \\
\vdots \\
A_n
\end{bmatrix}
= -\omega^2M
\begin{bmatrix}
A_1 \\
A_2 \\
A_3 \\
\vdots \\
A_n
\end{bmatrix}\]</p><p>The eigenvalues <span>$\omega^2$</span> are the eigenfrequencies of the vibrating string and the eigenvectors are the eigenmodes of the vibrating string.</p><p>Let us consider a 5-atom vibrating string with <span>$M = C = 1.0$</span>. We can find the eigenvalues and eigenvectors of the mass matrix using the <code>eigen</code> function.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; M = C = 1.0</code><code class="nohighlight hljs ansi" style="display:block;">1.0</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; C_matrix = [-C C 0 0 0; C -2C C 0 0; 0 C -2C C 0; 0 0 C -2C C; 0 0 0 C -C]</code><code class="nohighlight hljs ansi" style="display:block;">5×5 Matrix{Float64}:
 -1.0   1.0   0.0   0.0   0.0
  1.0  -2.0   1.0   0.0   0.0
  0.0   1.0  -2.0   1.0   0.0
  0.0   0.0   1.0  -2.0   1.0
  0.0   0.0   0.0   1.0  -1.0</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; evals, evecs = LinearAlgebra.eigen(C_matrix);</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; second_omega = sqrt(-evals[2]/M)</code><code class="nohighlight hljs ansi" style="display:block;">1.618033988749894</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; second_mode = evecs[:, 2]</code><code class="nohighlight hljs ansi" style="display:block;">5-element Vector{Float64}:
  0.37174803446018484
 -0.6015009550075462
  1.4023804401251382e-15
  0.601500955007545
 -0.3717480344601845</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; u(t) = second_mode .* cos.(-second_omega .* t) # (ϕi=0)</code><code class="nohighlight hljs ansi" style="display:block;">u (generic function with 1 method)</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; u(1.0)  # atom locations offsets at t=1.0</code><code class="nohighlight hljs ansi" style="display:block;">5-element Vector{Float64}:
 -0.017553977969578697
  0.028402932992545194
 -6.622053936793937e-17
 -0.028402932992545135
  0.01755397796957868</code></pre><p>By comparing the eigenmodes with the simulation, we can see that the second mode matches the simulation.</p><img src="../../assets/images/springs-demo.gif" alt="eigenmodes" width="400"/><p>For any given initial condition, the displacement of the atoms can be expressed as a linear combination of the eigenmodes. To find a more generic implementation, please check the <a href="https://github.com/GiggleLiu/ScientificComputingForPhysicists/tree/main/lib/PhysicsSimulation">source code</a>.</p></div></div><h2 id="Matrix-functions"><a class="docs-heading-anchor" href="#Matrix-functions">Matrix functions</a><a id="Matrix-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Matrix-functions" title="Permalink"></a></h2><p>Suppose we have a matrix <span>$A \in \mathbb{C}^{n\times n}$</span> and an analytic function <span>$f$</span> defined with a power series</p><p class="math-container">\[f(A) = \sum_{i=0}^\infty a_i A^i.\]</p><p>To compute a matrix function, e.g. <span>$f(A) = e^A$</span>, we can use the following steps:</p><ol><li>Diagonalize the matrix <span>$A$</span> as <span>$A = PDP^{-1}$</span>, where <span>$D$</span> is a diagonal matrix and <span>$P$</span> is a matrix whose columns are the eigenvectors of <span>$A$</span>.</li><li>Compute the matrix function <span>$f(A)$</span> as <span>$f(A) = Pf(D)P^{-1}$</span>.</li><li>Compute the matrix function <span>$f(D)$</span> by applying the function <span>$f$</span> to the diagonal elements of <span>$D$</span>.</li><li>Compute the matrix function <span>$f(A)$</span> by multiplying the matrices <span>$P$</span>, <span>$f(D)$</span>, and <span>$P^{-1}$</span>, i.e. <span>$f(A) = P f(D) P^{-1}$</span>.</li></ol><div class="admonition is-info"><header class="admonition-header">Example</header><div class="admonition-body"><p>Let us consider the matrix</p><p class="math-container">\[A = \begin{bmatrix}
1 &amp; 2 \\
3 &amp; 4
\end{bmatrix}\]</p><p>We can compute the matrix function <span>$e^A$</span> using the <code>exp</code> function.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; A = [1 2; 3 4]</code><code class="nohighlight hljs ansi" style="display:block;">2×2 Matrix{Int64}:
 1  2
 3  4</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; exp(A)</code><code class="nohighlight hljs ansi" style="display:block;">2×2 Matrix{Float64}:
  51.969   74.7366
 112.105  164.074</code></pre><p>It is consistent with the result from the eigenvalue decomposition.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; D, P = LinearAlgebra.eigen(A)</code><code class="nohighlight hljs ansi" style="display:block;">LinearAlgebra.Eigen{Float64, Float64, Matrix{Float64}, Vector{Float64}}
values:
2-element Vector{Float64}:
 -0.3722813232690143
  5.372281323269014
vectors:
2×2 Matrix{Float64}:
 -0.824565  -0.415974
  0.565767  -0.909377</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; P * LinearAlgebra.Diagonal(exp.(D)) * inv(P)</code><code class="nohighlight hljs ansi" style="display:block;">2×2 Matrix{Float64}:
  51.969   74.7366
 112.105  164.074</code></pre></div></div><h2 id="Singular-Value-Decomposition"><a class="docs-heading-anchor" href="#Singular-Value-Decomposition">Singular Value Decomposition</a><a id="Singular-Value-Decomposition-1"></a><a class="docs-heading-anchor-permalink" href="#Singular-Value-Decomposition" title="Permalink"></a></h2><p>The singular value decomposition (SVD) of a matrix <span>$A\in \mathbb{C}^{m\times n}$</span> is a factorization of the form</p><p class="math-container">\[A = U \Sigma V^\dagger\]</p><p>where <span>$U\in \mathbb{C}^{m\times m}$</span> and <span>$V\in \mathbb{C}^{n\times n}$</span> are orthogonal matrices and <span>$\Sigma\in \mathbb{C}^{m\times n}$</span> is a diagonal matrix with non-negative real numbers on the diagonal. The singular value decomposition is a generalization of the eigenvalue decomposition for non-square matrices.</p><p>In Julia, we can find the singular value decomposition of a matrix using the <code>svd</code> function.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; A = [1 2; 3 4; 5 6]</code><code class="nohighlight hljs ansi" style="display:block;">3×2 Matrix{Int64}:
 1  2
 3  4
 5  6</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; svd(A)</code><code class="nohighlight hljs ansi" style="display:block;">LinearAlgebra.SVD{Float64, Float64, Matrix{Float64}, Vector{Float64}}
U factor:
3×2 Matrix{Float64}:
 -0.229848   0.883461
 -0.524745   0.240782
 -0.819642  -0.401896
singular values:
2-element Vector{Float64}:
 9.525518091565107
 0.5143005806586443
Vt factor:
2×2 Matrix{Float64}:
 -0.619629  -0.784894
 -0.784894   0.619629</code></pre><h2 id="Cholesky-Decomposition"><a class="docs-heading-anchor" href="#Cholesky-Decomposition">Cholesky Decomposition</a><a id="Cholesky-Decomposition-1"></a><a class="docs-heading-anchor-permalink" href="#Cholesky-Decomposition" title="Permalink"></a></h2><p>The Cholesky decomposition of a positive definite matrix <span>$A\in \mathbb{C}^{n\times n}$</span> is a factorization of the form</p><p class="math-container">\[A = LL^\dagger\]</p><p>where <span>$L\in \mathbb{C}^{n\times n}$</span> is a lower triangular matrix. The Cholesky decomposition is used to solve the linear system of equations <span>$Ax = b$</span> when <span>$A$</span> is symmetric and positive definite.</p><p>In Julia, we can find the Cholesky decomposition of a matrix using the <code>cholesky</code> function.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; A = [2 1; 1 3]</code><code class="nohighlight hljs ansi" style="display:block;">2×2 Matrix{Int64}:
 2  1
 1  3</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; cholesky(A)</code><code class="nohighlight hljs ansi" style="display:block;">LinearAlgebra.Cholesky{Float64, Matrix{Float64}}
U factor:
2×2 LinearAlgebra.UpperTriangular{Float64, Matrix{Float64}}:
 1.41421  0.707107
  ⋅       1.58114</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../chap2/julia-fluid/">« Project: Fluid dynamics</a><a class="docs-footer-nextpage" href="../lu/">Solving linear equations by LU factorization: Bottom-up »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Tuesday 26 March 2024 01:38">Tuesday 26 March 2024</span>. Using Julia version 1.10.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
