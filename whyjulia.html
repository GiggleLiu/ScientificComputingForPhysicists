<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Yu-Sheng Zhao" />
  <meta name="author" content="Yi-Dai Zhang" />
  <meta name="author" content="Jin-Guo Liu" />
  <title>Why Julia is fast? - Scientific Computing for Physicist</title>
  <link rel="shortcut icon" type="image/png" href="/favicon.png"/>
  <link rel="stylesheet" href="/style.css"/>
    <script src="/mousetrap.min.js"></script>
    <style>
  @font-face {
    font-family: JuliaMono-Regular;
    src: url("/JuliaMono-Regular.woff2");
  }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <link rel="stylesheet" href="/github.min.css">
<script src="/highlight.min.js"></script>
<script src="/julia.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', (event) => {
    document.querySelectorAll('pre').forEach((el) => {
        if (!el.classList.contains('output')) {
            hljs.highlightElement(el);
        }
    });
});
</script>
 
</head>
<body>
<script>
function click_next() {
  var next = document.getElementById('nav-next');
  next.firstElementChild.nextElementSibling.click();
}
function click_prev() {
  var prev = document.getElementById('nav-prev');
  prev.firstElementChild.click();
}
Mousetrap.bind('right', click_next);
Mousetrap.bind('h', click_prev);
Mousetrap.bind('left', click_prev);
Mousetrap.bind('l', click_next);
</script>

<div class="books-container">
<aside class="books-menu">
<input type="checkbox" id="menu">
<label for="menu">☰</label>
<div class="books-title">
<a href="/">Scientific Computing for Physicist</a>
</div><br />
<span class="books-subtitle">
with Julia programming language
</span>
<div class="books-menu-content">
<li><a class="menu-level-1" href="/open-source-dev-toolchains"><b>1</b> Becoming an Open-Source De..</a></li>
<li><a class="menu-level-2" href="/terminal"><b>1.1</b> Get a Terminal!</a></li>
<li><a class="menu-level-2" href="/version-control"><b>1.2</b> Maintainability - Versio..</a></li>
<li><a class="menu-level-2" href="/ci-cd"><b>1.3</b> Correctness - Unit Tests</a></li>
<li><a class="menu-level-1" href="/julia"><b>2</b> Julia</a></li>
<li><a class="menu-level-2" href="/setup"><b>2.1</b> Setup Julia</a></li>
<li><a class="menu-level-2" href="/whyjulia"><b>2.2</b> Why Julia is fast?</a></li>
<li><a class="menu-level-2" href="/type-and-multiple-dispatch"><b>2.3</b> Type and Multiple-dispat..</a></li>
<li><a class="menu-level-2" href="/tuple-array-and-broadcasting"><b>2.4</b> Tuple, Array and broadca..</a></li>
<li><a class="menu-level-2" href="/publishing-package"><b>2.5</b> Publishing a Package</a></li>
<li><a class="menu-level-1" href="/appendix"><b></b> Appendix</a></li>
<li><a class="menu-level-1" href="/references"><b>3</b> References</a></li>
</div>
</aside>

<div class="books-content">
<h2 data-number="2.2" id="sec:whyjulia"><span class="header-section-number">2.2</span> Why Julia is fast?</h2>
<h3 data-number="2.2.1" id="what-is-julia-programming-language"><span class="header-section-number">2.2.1</span> What is Julia programming language?</h3>
<p>Julia is a modern, open-source, high performance programming language for technical computing. It was born in 2012 in MIT, now is maintained by JuliaHub Inc. located in Boston, US.</p>
<p><em>Julia is open-source.</em> Julia source code is maintained on GitHub repo <a href="https://github.com/JuliaLang/julia">JuliaLang/julia</a>, and it open-source LICENSE is MIT. Julia packages can be found on <a href="https://juliahub.com/ui/Packages">JuliaHub</a>, most of them are open-source.</p>
<p><em>Julia is designed for high performance</em> (<a href="https://arxiv.org/abs/1209.5145">arXiv:1209.5145</a>). It is a dynamic programming language, but it is as fast as C/C++. The following figure shows the computing time of multiple programming languages normalized to C/C++. <img src="./assets/images/benchmark.png" alt="image" width="500" height="auto"></p>
<p><em>Julia is a trend in scientific computing.</em> Many famous scientists and engineers have switched to Julia from other programming languages.</p>
<ul>
<li><strong>Steven G. Johnson</strong>, creater of <a href="http://www.fftw.org/">FFTW</a>, switched from C++ to Julia years ago.</li>
<li><strong>Anders Sandvik</strong>, creater of Stochastic Series Expansion (SSE) quantum Monte Carlo method, switched from Fortran to Julia recently.
<ul>
<li>Course link: <a href="https://physics.bu.edu/~py502/">Computational Physics</a></li>
</ul></li>
<li><strong>Miles Stoudenmire</strong>, creater of <a href="https://itensor.org/">ITensor</a>, switched from C++ to Julia years ago.</li>
<li><strong>Jutho Haegeman</strong>, <strong>Chris Rackauckas</strong> and more.</li>
</ul>
<blockquote>
<p><strong>FAQ: Should I switch to Julia?</strong></p>
<p>Before switching to Julia, please make sure:</p>
<ul>
<li>the problem you are trying to solve runs more than 10min.</li>
<li>you are not satisfied by any existing tools.</li>
</ul>
</blockquote>
<h3 data-number="2.2.2" id="my-first-program-factorial"><span class="header-section-number">2.2.2</span> My first program: Factorial</h3>
<p>Before we start, please make sure you have the needed packages installed. Type <code>]</code> in the Julia REPL to enter the package manager, and then type</p>
<pre class="julia"><code>pkg&gt; add BenchmarkTools, MethodAnalysis</code></pre>
<p>Go back to the REPL by pressing <code>Backspace</code>.</p>
<pre class="julia"><code>julia&gt; function jlfactorial(n)
           x = 1
           for i in 1:n
               x = x * i
           end
           return x
       end
jlfactorial (generic function with 1 method)</code></pre>
<p>To make sure the performance is measured correctly, we use the <code>@btime</code> macro in the <code>BenchmarkTools</code> package to measure the performance of the function.</p>
<pre class="julia"><code>julia&gt; @btime jlfactorial(x) setup=(x=5)
2.208 ns (0 allocations: 0 bytes)
120</code></pre>
<p>CPU clock cycle is ~0.3ns, so it takes only a few clock cycles to compute the factorial of 5. Julia is really fast!</p>
<h3 data-number="2.2.3" id="compare-with-the-speed-of-c-program"><span class="header-section-number">2.2.3</span> Compare with the speed of C program</h3>
<p>To measure the performance of the C program, we can utilize the benchmark utilities in Julia. Benchmarking C program with Julia is accurate because Julia has perfect interoperability with C, which allows zero-cost calling of C functions.</p>
<p>In the following example, we first write a C program to calculate the factorial of a number. The file is named <code>demo.c</code>, and the content is as follows:</p>
<pre class="bash"><code>$ cat demo.c
#include &lt;stddef.h&gt;
int c_factorial(size_t n) {
    int s = 1;
    for (size_t i=1; i&lt;=n; i++) {
        s *= i;
    }
    return s;
}</code></pre>
<p>To execute a C program in Julia, one needs to compile it to a shared library.</p>
<pre><code>$ gcc demo.c -fPIC -O3 -shared -o demo.so</code></pre>
<p>To call the function in Julia, one can use the <code>@ccall</code> macro in the <code>Libdl</code> package (<a href="https://docs.julialang.org/en/v1/manual/calling-c-and-fortran-code/">learn more</a>). Please open a Julia REPL and execute the following code:</p>
<pre class="julia"><code>julia&gt; using Libdl

julia&gt; c_factorial(x) = Libdl.@ccall &quot;./demo.so&quot;.c_factorial(x::Csize_t)::Int</code></pre>
<p>The benchmark result is as follows:</p>
<pre class="julia"><code>julia&gt; using BenchmarkTools

julia&gt; @benchmark c_factorial(5)
BenchmarkTools.Trial: 10000 samples with 1000 evaluations.
 Range (min … max):  7.333 ns … 47.375 ns  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     7.458 ns              ┊ GC (median):    0.00%
 Time  (mean ± σ):   7.764 ns ±  1.620 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%

  ██▅  ▃▁ ▂▂                         ▁▁▁                     ▂
  ███▆▄██▆███▅▅▆▆▆▅▆▅▄▅▆▅▅▇▆▆▄▅▅▇█▇▆▆█████▅▃▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▃ █
  7.33 ns      Histogram: log(frequency) by time     12.6 ns &lt;

 Memory estimate: 0 bytes, allocs estimate: 0.</code></pre>
<p>Although the C program requires the type of variables to be manually declared, its performance is very good. The computing time is only 7.33 ns.</p>
<h3 data-number="2.2.4" id="compare-with-the-speed-of-python-program"><span class="header-section-number">2.2.4</span> Compare with the speed of Python program</h3>
<p>We use the <code>timeit</code> module in ipython to measure the performance of the Python program.</p>
<pre class="ipython"><code>In [5]: def factorial(n):
...:        x = 1
...:        for i in range(1, n+1):
...:            x = x * i
...:        return x
...:

In [6]: factorial(5)
Out[6]: 120

In [7]: timeit factorial(5)
144 ns ± 0.379 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)

In [8]: factorial(100)
Out[8]: 93326215443944152681699238856266700490715968264381621468592963895217599993229915608941463976156518286253697920827223758251185210916864000000000000000000000000</code></pre>
<p>One can also use the <code>PyCall</code> package to call the Python function in Julia.</p>
<p>The computing time of the Python program is 144 ns, which is 20 times slower than the C program and 70 times slower than the Julia program. On the other hand, the python program is more flexible since its integer type is not limited by the machine word size.</p>
<pre class="julia"><code>julia&gt; typemax(Int)
9223372036854775807

julia&gt; jlfactorial(100)
0</code></pre>
<p>The reason why python is slow and flexible are the same. In python the type of a variable is not declared when it is defined, and it can be changed at any time. This is why the integer type becomes an arbitrary precision integer type when the number is too large. If a variable does not have a fixed type, the program can not preallocate memory for it due to the lack of size information. Then a dynamic typed language has to use a tuple <code>(type, *data)</code> to represent an object, where <code>type</code> is the type of the object and <code>*data</code> is the pointer to the data. Pointing to a random memory location is slow, because it violates the principle of data locality. Lacking of data locality causes the frequent cache miss - failure to find the data in the L1, L2, or L3 cache. Loading data from the main memory is slow, because of the long latency of reading the main memory.</p>
<p><img src="./assets/images/data.png" alt="image" width="300" height="auto"></p>
<h3 data-number="2.2.5" id="combining-python-and-cc"><span class="header-section-number">2.2.5</span> Combining Python and C/C++?</h3>
<p>From the maintainer’s perspective, it is hard to maintain a program written in both Python and C/C++: - It makes the build configuration files complicated. - Learning two programming languages is hard for new contributors.</p>
<p>Using python as glue is not as powerful as it looks, the following problem can not be solved by this approach: - Monte Carlo simulation. - Branching and bound algorithms.</p>
<p><img src="./assets/images/pythonc.png" alt="image" width="500" height="auto"></p>
<h3 data-number="2.2.6" id="julias-solution-just-in-time-jit-compilation"><span class="header-section-number">2.2.6</span> Julia’s solution: Just in time (JIT) compilation</h3>
<p>Given that you have defined a Julia function, the Julia compiler will generate a binary for the function when it is called for the first time. The binary is called a <strong>method instance</strong>, and it is generated based on the <strong>input types</strong> of the function. The method instance is then stored in the method table, and it will be called when the function is called with the same input types. The method instance is generated by the LLVM compiler, and it is optimized for the input types. The method instance is a binary, and it is as fast as a C/C++ program.</p>
<p><strong>Step 1: Infer the types</strong></p>
<pre class="julia"><code>julia&gt; @code_warntype jlfactorial(10)
MethodInstance for jlfactorial(::Int64)
  from jlfactorial(n) @ Main REPL[4]:1
Arguments
  #self#::Core.Const(jlfactorial)
  n::Int64
Locals
  @_3::Union{Nothing, Tuple{Int64, Int64}}
  x::Int64
  i::Int64
Body::Int64
1 ─       (x = 1)
│   %2  = (1:n)::Core.PartialStruct(UnitRange{Int64}, Any[Core.Const(1), Int64])
│         (@_3 = Base.iterate(%2))
│   %4  = (@_3 === nothing)::Bool
│   %5  = Base.not_int(%4)::Bool
└──       goto #4 if not %5
2 ┄ %7  = @_3::Tuple{Int64, Int64}
│         (i = Core.getfield(%7, 1))
│   %9  = Core.getfield(%7, 2)::Int64
│         (x = x * i)
│         (@_3 = Base.iterate(%2, %9))
│   %12 = (@_3 === nothing)::Bool
│   %13 = Base.not_int(%12)::Bool
└──       goto #4 if not %13
3 ─       goto #2
4 ┄       return x</code></pre>
<p>When type inference fails</p>
<pre class="julia"><code>julia&gt; badcode(x) = x &gt; 3 ? 1.0 : 3

julia&gt; @code_warntype badcode(4)
MethodInstance for badcode(::Int64)
  from badcode(x) @ Main REPL[9]:1
Arguments
  #self#::Core.Const(badcode)
  x::Int64
Body::Union{Float64, Int64}
1 ─ %1 = (x &gt; 3)::Bool
└──      goto #3 if not %1
2 ─      return 1.0
3 ─      return 3</code></pre>
<p><code>Union{Float64, Int64}</code> means the return type is either <code>Float64</code> or <code>Int64</code>.</p>
<p>Type unstable code is slow</p>
<pre class="julia"><code>julia&gt; x = rand(1:10, 1000);

julia&gt; @benchmark badcode.($x)
BenchmarkTools.Trial: 10000 samples with 8 evaluations.
 Range (min … max):  2.927 μs … 195.198 μs  ┊ GC (min … max):  0.00% … 96.52%
 Time  (median):     3.698 μs               ┊ GC (median):     0.00%
 Time  (mean ± σ):   4.257 μs ±   7.894 μs  ┊ GC (mean ± σ):  12.43% ±  6.54%

                 ▁▅█▅▃▂                                        
  ▁▃▅▇▇▇▅▃▂▂▂▃▄▆▇███████▇▇▅▄▄▃▃▃▃▃▃▂▂▃▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁ ▃
  2.93 μs         Histogram: frequency by time        5.44 μs &lt;

 Memory estimate: 26.72 KiB, allocs estimate: 696.

julia&gt; stable(x) = x &gt; 3 ? 1.0 : 3.0
stable (generic function with 1 method)

julia&gt; @benchmark stable.($x)
BenchmarkTools.Trial: 10000 samples with 334 evaluations.
 Range (min … max):  213.820 ns … 25.350 μs  ┊ GC (min … max):  0.00% … 98.02%
 Time  (median):     662.551 ns              ┊ GC (median):     0.00%
 Time  (mean ± σ):   947.978 ns ±  1.187 μs  ┊ GC (mean ± σ):  29.30% ± 21.05%

  ▂▃▅██▇▅▄▃▂▁                                                  ▂
  ████████████▇▅▅▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▃▅▆▇██████▇▇▇▆█▇▇▇▇▇▇▇▇▆▇▆▆▆▇▇ █
  214 ns        Histogram: log(frequency) by time      6.32 μs &lt;

 Memory estimate: 7.94 KiB, allocs estimate: 1.</code></pre>
<ul>
<li>“<code>.</code>” is the broadcasting operator.</li>
<li>“<code>$</code>” is the interpolation operator, it is used to interpolate a variable into an expression.</li>
</ul>
<p><strong>Step 2: Generates the LLVM intermediate representation</strong></p>
<p>LLVM is a set of compiler and toolchain technologies that can be used to develop a front end for any programming language and a back end for any instruction set architecture. LLVM is the backend of multiple languages, including Julia, Rust, Swift and Kotlin.</p>
<pre class="julia"><code>julia&gt; @code_llvm jlfactorial(10)

or any instruction set architecture. LLVM is the backend of multiple languages, including Julia, Rust, Swift and Kotlin.



;  @ /Users/liujinguo/jcode/ModernScientificComputing2024/Lecture2/3.julia.jl#==#d2429055-58e9-4d84-894f-2e639723e078:1 within `jlfactorial`
define i64 @julia_jlfactorial_3677(i64 signext %0) #0 {
top:
;  @ /Users/liujinguo/jcode/ModernScientificComputing2024/Lecture2/3.julia.jl#==#d2429055-58e9-4d84-894f-2e639723e078:3 within `jlfactorial`
; ┌ @ range.jl:5 within `Colon`
; │┌ @ range.jl:403 within `UnitRange`
; ││┌ @ range.jl:414 within `unitrange_last`
     %1 = call i64 @llvm.smax.i64(i64 %0, i64 0)
; └└└
; ┌ @ range.jl:897 within `iterate`
; │┌ @ range.jl:672 within `isempty`
; ││┌ @ operators.jl:378 within `&gt;`
; │││┌ @ int.jl:83 within `&lt;`
      %2 = icmp slt i64 %0, 1
; └└└└
  br i1 %2, label %L32, label %L17.preheader

L17.preheader:                                    ; preds = %top
;  @ /Users/liujinguo/jcode/ModernScientificComputing2024/Lecture2/3.julia.jl#==#d2429055-58e9-4d84-894f-2e639723e078:5 within `jlfactorial`
  %min.iters.check = icmp ult i64 %1, 2
  br i1 %min.iters.check, label %scalar.ph, label %vector.ph

vector.ph:                                        ; preds = %L17.preheader
  %n.vec = and i64 %1, 9223372036854775806
  %ind.end = or i64 %1, 1
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %induction12, %vector.body ]
  %vec.phi = phi i64 [ 1, %vector.ph ], [ %3, %vector.body ]
  %vec.phi11 = phi i64 [ 1, %vector.ph ], [ %4, %vector.body ]
  %offset.idx = or i64 %index, 1
  %induction12 = add i64 %index, 2
;  @ /Users/liujinguo/jcode/ModernScientificComputing2024/Lecture2/3.julia.jl#==#d2429055-58e9-4d84-894f-2e639723e078:4 within `jlfactorial`
; ┌ @ int.jl:88 within `*`
   %3 = mul i64 %vec.phi, %offset.idx
   %4 = mul i64 %vec.phi11, %induction12
   %5 = icmp eq i64 %induction12, %n.vec
   br i1 %5, label %middle.block, label %vector.body

middle.block:                                     ; preds = %vector.body
; └
;  @ /Users/liujinguo/jcode/ModernScientificComputing2024/Lecture2/3.julia.jl#==#d2429055-58e9-4d84-894f-2e639723e078:5 within `jlfactorial`
  %bin.rdx = mul i64 %4, %3
  %cmp.n = icmp eq i64 %1, %n.vec
  br i1 %cmp.n, label %L32, label %scalar.ph

scalar.ph:                                        ; preds = %middle.block, %L17.preheader
  %bc.resume.val = phi i64 [ %ind.end, %middle.block ], [ 1, %L17.preheader ]
  %bc.merge.rdx = phi i64 [ %bin.rdx, %middle.block ], [ 1, %L17.preheader ]
  br label %L17

L17:                                              ; preds = %L17, %scalar.ph
  %value_phi4 = phi i64 [ %7, %L17 ], [ %bc.resume.val, %scalar.ph ]
  %value_phi6 = phi i64 [ %6, %L17 ], [ %bc.merge.rdx, %scalar.ph ]
;  @ /Users/liujinguo/jcode/ModernScientificComputing2024/Lecture2/3.julia.jl#==#d2429055-58e9-4d84-894f-2e639723e078:4 within `jlfactorial`
; ┌ @ int.jl:88 within `*`
   %6 = mul i64 %value_phi6, %value_phi4
; └
;  @ /Users/liujinguo/jcode/ModernScientificComputing2024/Lecture2/3.julia.jl#==#d2429055-58e9-4d84-894f-2e639723e078:5 within `jlfactorial`
; ┌ @ range.jl:901 within `iterate`
; │┌ @ promotion.jl:521 within `==`
    %.not = icmp eq i64 %value_phi4, %1
; │└
   %7 = add nuw i64 %value_phi4, 1
; └
  br i1 %.not, label %L32, label %L17

L32:                                              ; preds = %L17, %middle.block, %top
  %value_phi10 = phi i64 [ 1, %top ], [ %bin.rdx, %middle.block ], [ %6, %L17 ]
;  @ /Users/liujinguo/jcode/ModernScientificComputing2024/Lecture2/3.julia.jl#==#d2429055-58e9-4d84-894f-2e639723e078:6 within `jlfactorial`
  ret i64 %value_phi10
}</code></pre>
<p><strong>Step 3: Compiles to binary code</strong></p>
<pre class="julia"><code>julia&gt; @code_native jlfactorial(10)
    .section    __TEXT,__text,regular,pure_instructions
    .build_version macos, 14, 0
    .globl  _julia_jlfactorial_3726         ; -- Begin function julia_jlfactorial_3726
    .p2align    2
_julia_jlfactorial_3726:                ; @julia_jlfactorial_3726
; ┌ @ /Users/liujinguo/jcode/ModernScientificComputing2024/Lecture2/3.julia.jl#==#d2429055-58e9-4d84-894f-2e639723e078:1 within `jlfactorial`
; %bb.0:                                ; %top
; │ @ /Users/liujinguo/jcode/ModernScientificComputing2024/Lecture2/3.julia.jl#==#d2429055-58e9-4d84-894f-2e639723e078:3 within `jlfactorial`
; │┌ @ range.jl:5 within `Colon`
; ││┌ @ range.jl:403 within `UnitRange`
; │││┌ @ range.jl:414 within `unitrange_last`
    cmp x0, #0
    csel    x9, x0, xzr, gt
; │└└└
    cmp x0, #1
    b.lt    LBB0_3
; %bb.1:                                ; %L17.preheader
; │ @ /Users/liujinguo/jcode/ModernScientificComputing2024/Lecture2/3.julia.jl#==#d2429055-58e9-4d84-894f-2e639723e078:5 within `jlfactorial`
    cmp x9, #2
    b.hs    LBB0_4
; %bb.2:
    mov w8, #1
    mov w0, #1
    b   LBB0_7
LBB0_3:
    mov w0, #1
; │ @ /Users/liujinguo/jcode/ModernScientificComputing2024/Lecture2/3.julia.jl#==#d2429055-58e9-4d84-894f-2e639723e078:6 within `jlfactorial`
    ret
LBB0_4:                                 ; %vector.ph
    mov x12, #0
; │ @ /Users/liujinguo/jcode/ModernScientificComputing2024/Lecture2/3.julia.jl#==#d2429055-58e9-4d84-894f-2e639723e078:5 within `jlfactorial`
    and x10, x9, #0x7ffffffffffffffe
    orr x8, x9, #0x1
    mov w11, #1
    mov w13, #1
LBB0_5:                                 ; %vector.body
                                        ; =&gt;This Inner Loop Header: Depth=1
; │ @ /Users/liujinguo/jcode/ModernScientificComputing2024/Lecture2/3.julia.jl#==#d2429055-58e9-4d84-894f-2e639723e078:4 within `jlfactorial`
; │┌ @ int.jl:88 within `*`
    madd    x11, x11, x12, x11
; │└
; │ @ /Users/liujinguo/jcode/ModernScientificComputing2024/Lecture2/3.julia.jl#==#d2429055-58e9-4d84-894f-2e639723e078:5 within `jlfactorial`
    add x14, x12, #2
; │ @ /Users/liujinguo/jcode/ModernScientificComputing2024/Lecture2/3.julia.jl#==#d2429055-58e9-4d84-894f-2e639723e078:4 within `jlfactorial`
; │┌ @ int.jl:88 within `*`
    mul x13, x13, x14
    mov x12, x14
    cmp x10, x14
    b.ne    LBB0_5
; %bb.6:                                ; %middle.block
; │└
; │ @ /Users/liujinguo/jcode/ModernScientificComputing2024/Lecture2/3.julia.jl#==#d2429055-58e9-4d84-894f-2e639723e078:5 within `jlfactorial`
    mul x0, x13, x11
    cmp x9, x10
    b.eq    LBB0_9
LBB0_7:                                 ; %L17.preheader15
    add x9, x9, #1
LBB0_8:                                 ; %L17
                                        ; =&gt;This Inner Loop Header: Depth=1
; │ @ /Users/liujinguo/jcode/ModernScientificComputing2024/Lecture2/3.julia.jl#==#d2429055-58e9-4d84-894f-2e639723e078:4 within `jlfactorial`
; │┌ @ int.jl:88 within `*`
    mul x0, x0, x8
; │└
; │ @ /Users/liujinguo/jcode/ModernScientificComputing2024/Lecture2/3.julia.jl#==#d2429055-58e9-4d84-894f-2e639723e078:5 within `jlfactorial`
; │┌ @ range.jl:901 within `iterate`
    add x8, x8, #1
; │└
    cmp x9, x8
    b.ne    LBB0_8
LBB0_9:                                 ; %L32
; │ @ /Users/liujinguo/jcode/ModernScientificComputing2024/Lecture2/3.julia.jl#==#d2429055-58e9-4d84-894f-2e639723e078:6 within `jlfactorial`
    ret
; └
                                        ; -- End function
.subsections_via_symbols</code></pre>
<pre class="julia"><code>julia&gt; methods(jlfactorial)
# 1 method for generic function &quot;jlfactorial&quot; from Main:
 [1] jlfactorial(n)
     @ REPL[4]:1</code></pre>
<pre class="julia"><code>julia&gt; using MethodAnalysis

julia&gt; methodinstances(jlfactorial)
1-element Vector{Core.MethodInstance}:
 MethodInstance for jlfactorial(::Int64)</code></pre>
<p>Single method, multiple instances</p>
<pre class="julia"><code>julia&gt; jlfactorial(UInt32(5))
120

julia&gt; methodinstances(jlfactorial)
2-element Vector{Core.MethodInstance}:
 MethodInstance for jlfactorial(::Int64)
 MethodInstance for jlfactorial(::UInt32)</code></pre>
<h3 data-number="2.2.7" id="summary-key-ingredients-of-performance"><span class="header-section-number">2.2.7</span> Summary: Key ingredients of performance</h3>
<ul>
<li><strong>JIT</strong> compilation: compile the code with <strong>LLVM</strong> compiler framework when a method is called for the first time;</li>
<li><strong>Multiple dispatch</strong>: invoke the correct method instance according to the type of multiple arguments;</li>
</ul>


<div class="bottom-nav">
    <p id="nav-prev" style="text-align: left;">
        <a class="menu-level-2" href="/setup"><b>2.1</b> Setup Julia</a> <kbd>←</kbd>
        <span id="nav-next" style="float: right;">
            <kbd>→</kbd> <a class="menu-level-2" href="/type-and-multiple-dispatch"><b>2.3</b> Type and Multiple-dispat..</a>
        </span>
    </p>
</div>


<div class="license">
    <br/>
  <br/>
  <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a>
    Yu-Sheng Zhao, Yi-Dai Zhang, Jin-Guo Liu
</div>
</div>
</div>
</body>
</html>